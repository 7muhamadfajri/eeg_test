{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ac01af1-64a0-4e0e-8cc7-8a876fe82fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"All-baca-7040x73.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dca8977d-04d4-40bf-b14b-4df9fc75a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "rng = RandomState()\n",
    "df = pd.read_csv(\"All-baca-7040x73.csv\")\n",
    "train = df.sample(frac=0.7, random_state=rng)\n",
    "test = df.loc[~df.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "730a6820-adfb-4dbf-92dc-377b93bd016d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAUS      624\n",
       "TOILET    624\n",
       "LAPAR     620\n",
       "MAKAN     619\n",
       "SENANG    618\n",
       "MINUM     613\n",
       "SEDIH     608\n",
       "SAKIT     602\n",
       "Name: KATA, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['KATA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89e7b0de-b577-4559-b68d-787717b1d540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKIT     278\n",
       "SEDIH     272\n",
       "MINUM     267\n",
       "SENANG    262\n",
       "MAKAN     261\n",
       "LAPAR     260\n",
       "HAUS      256\n",
       "TOILET    256\n",
       "Name: KATA, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['KATA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a7d144f-676e-4f47-9477-210137bba0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Predictors and Outcome values from train and test sets\n",
    "X_train = pd.DataFrame(train.drop(['SUBJEK','KATA'],axis=1))\n",
    "\n",
    "\n",
    "X_test = pd.DataFrame(test.drop(['SUBJEK','KATA'],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81176b18-2d1e-465e-841b-24022dcac90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>F7_THETA</th>\n",
       "      <th>F7_ALPHA</th>\n",
       "      <th>F7_LOW_BETA</th>\n",
       "      <th>F7_HIGH_BETA</th>\n",
       "      <th>...</th>\n",
       "      <th>F8_THETA</th>\n",
       "      <th>F8_ALPHA</th>\n",
       "      <th>F8_LOW_BETA</th>\n",
       "      <th>F8_HIGH_BETA</th>\n",
       "      <th>F8_GAMMA</th>\n",
       "      <th>AF4_THETA</th>\n",
       "      <th>AF4_ALPHA</th>\n",
       "      <th>AF4_LOW_BETA</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>17</td>\n",
       "      <td>0.969157</td>\n",
       "      <td>0.419813</td>\n",
       "      <td>0.250860</td>\n",
       "      <td>0.187390</td>\n",
       "      <td>0.065156</td>\n",
       "      <td>0.885038</td>\n",
       "      <td>0.578492</td>\n",
       "      <td>0.466285</td>\n",
       "      <td>0.239371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800284</td>\n",
       "      <td>0.288642</td>\n",
       "      <td>0.144675</td>\n",
       "      <td>0.206214</td>\n",
       "      <td>0.229648</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.018381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>7</td>\n",
       "      <td>0.553792</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.282370</td>\n",
       "      <td>0.298493</td>\n",
       "      <td>0.129987</td>\n",
       "      <td>0.633558</td>\n",
       "      <td>0.486767</td>\n",
       "      <td>0.389702</td>\n",
       "      <td>0.455692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871469</td>\n",
       "      <td>0.469115</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.269455</td>\n",
       "      <td>0.207066</td>\n",
       "      <td>1.218318</td>\n",
       "      <td>0.382762</td>\n",
       "      <td>0.806457</td>\n",
       "      <td>0.413249</td>\n",
       "      <td>0.250350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>22</td>\n",
       "      <td>14.952279</td>\n",
       "      <td>3.280859</td>\n",
       "      <td>0.529933</td>\n",
       "      <td>0.506541</td>\n",
       "      <td>0.332382</td>\n",
       "      <td>23.593871</td>\n",
       "      <td>1.705054</td>\n",
       "      <td>1.081661</td>\n",
       "      <td>1.232416</td>\n",
       "      <td>...</td>\n",
       "      <td>11.597608</td>\n",
       "      <td>2.486005</td>\n",
       "      <td>0.388443</td>\n",
       "      <td>1.563786</td>\n",
       "      <td>1.344028</td>\n",
       "      <td>12.899495</td>\n",
       "      <td>3.239416</td>\n",
       "      <td>0.455126</td>\n",
       "      <td>0.828596</td>\n",
       "      <td>0.464897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>12</td>\n",
       "      <td>1.564874</td>\n",
       "      <td>3.649904</td>\n",
       "      <td>0.206752</td>\n",
       "      <td>0.444108</td>\n",
       "      <td>0.245853</td>\n",
       "      <td>3.166249</td>\n",
       "      <td>2.514987</td>\n",
       "      <td>0.973730</td>\n",
       "      <td>0.419433</td>\n",
       "      <td>...</td>\n",
       "      <td>2.315902</td>\n",
       "      <td>2.599993</td>\n",
       "      <td>0.828052</td>\n",
       "      <td>0.294634</td>\n",
       "      <td>0.148104</td>\n",
       "      <td>1.685567</td>\n",
       "      <td>3.248761</td>\n",
       "      <td>1.279734</td>\n",
       "      <td>0.626797</td>\n",
       "      <td>0.236227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>32</td>\n",
       "      <td>2.506063</td>\n",
       "      <td>1.075268</td>\n",
       "      <td>1.054692</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>1.159595</td>\n",
       "      <td>0.428635</td>\n",
       "      <td>0.463035</td>\n",
       "      <td>0.699421</td>\n",
       "      <td>...</td>\n",
       "      <td>2.426510</td>\n",
       "      <td>2.457515</td>\n",
       "      <td>1.414658</td>\n",
       "      <td>1.308107</td>\n",
       "      <td>0.385595</td>\n",
       "      <td>2.318869</td>\n",
       "      <td>1.075982</td>\n",
       "      <td>2.143163</td>\n",
       "      <td>2.837157</td>\n",
       "      <td>0.744531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>37</td>\n",
       "      <td>51.565604</td>\n",
       "      <td>3.391266</td>\n",
       "      <td>1.835776</td>\n",
       "      <td>0.808303</td>\n",
       "      <td>0.296889</td>\n",
       "      <td>19.835506</td>\n",
       "      <td>1.089665</td>\n",
       "      <td>0.737173</td>\n",
       "      <td>0.687855</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642095</td>\n",
       "      <td>0.616125</td>\n",
       "      <td>0.234319</td>\n",
       "      <td>0.297825</td>\n",
       "      <td>0.266174</td>\n",
       "      <td>53.489877</td>\n",
       "      <td>4.621722</td>\n",
       "      <td>2.171978</td>\n",
       "      <td>0.809025</td>\n",
       "      <td>0.263999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>27</td>\n",
       "      <td>7.756195</td>\n",
       "      <td>2.240452</td>\n",
       "      <td>0.848055</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>0.413748</td>\n",
       "      <td>7.974846</td>\n",
       "      <td>1.066862</td>\n",
       "      <td>0.665752</td>\n",
       "      <td>0.486006</td>\n",
       "      <td>...</td>\n",
       "      <td>7.430139</td>\n",
       "      <td>4.179854</td>\n",
       "      <td>2.339862</td>\n",
       "      <td>0.663899</td>\n",
       "      <td>0.335339</td>\n",
       "      <td>25.352437</td>\n",
       "      <td>6.233271</td>\n",
       "      <td>1.161865</td>\n",
       "      <td>0.844477</td>\n",
       "      <td>0.775728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>7</td>\n",
       "      <td>12.596277</td>\n",
       "      <td>2.305350</td>\n",
       "      <td>1.429092</td>\n",
       "      <td>2.475099</td>\n",
       "      <td>0.940114</td>\n",
       "      <td>2.770743</td>\n",
       "      <td>0.700636</td>\n",
       "      <td>0.681848</td>\n",
       "      <td>1.568421</td>\n",
       "      <td>...</td>\n",
       "      <td>2.919247</td>\n",
       "      <td>0.425634</td>\n",
       "      <td>0.571025</td>\n",
       "      <td>0.874110</td>\n",
       "      <td>0.416580</td>\n",
       "      <td>16.017680</td>\n",
       "      <td>1.519394</td>\n",
       "      <td>1.255895</td>\n",
       "      <td>2.342372</td>\n",
       "      <td>1.076702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>2</td>\n",
       "      <td>1.380722</td>\n",
       "      <td>0.367982</td>\n",
       "      <td>0.225017</td>\n",
       "      <td>0.254739</td>\n",
       "      <td>0.215541</td>\n",
       "      <td>2.050639</td>\n",
       "      <td>0.539228</td>\n",
       "      <td>0.201793</td>\n",
       "      <td>0.455422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557181</td>\n",
       "      <td>0.693332</td>\n",
       "      <td>0.579581</td>\n",
       "      <td>0.239018</td>\n",
       "      <td>0.158849</td>\n",
       "      <td>2.682565</td>\n",
       "      <td>0.769564</td>\n",
       "      <td>0.454318</td>\n",
       "      <td>0.324629</td>\n",
       "      <td>0.216097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>12</td>\n",
       "      <td>3.235238</td>\n",
       "      <td>1.500663</td>\n",
       "      <td>0.961854</td>\n",
       "      <td>0.487098</td>\n",
       "      <td>0.146348</td>\n",
       "      <td>3.692103</td>\n",
       "      <td>2.362193</td>\n",
       "      <td>2.142775</td>\n",
       "      <td>0.722593</td>\n",
       "      <td>...</td>\n",
       "      <td>36.643787</td>\n",
       "      <td>9.464797</td>\n",
       "      <td>3.646966</td>\n",
       "      <td>2.416778</td>\n",
       "      <td>0.659013</td>\n",
       "      <td>6.884388</td>\n",
       "      <td>2.696627</td>\n",
       "      <td>2.163959</td>\n",
       "      <td>1.846503</td>\n",
       "      <td>0.522795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4928 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LABEL  AF3_THETA  AF3_ALPHA  AF3_LOW_BETA  AF3_HIGH_BETA  AF3_GAMMA  \\\n",
       "1332     17   0.969157   0.419813      0.250860       0.187390   0.065156   \n",
       "6298      7   0.553792   0.297000      0.282370       0.298493   0.129987   \n",
       "3276     22  14.952279   3.280859      0.529933       0.506541   0.332382   \n",
       "5290     12   1.564874   3.649904      0.206752       0.444108   0.245853   \n",
       "997      32   2.506063   1.075268      1.054692       0.957324   0.467257   \n",
       "...     ...        ...        ...           ...            ...        ...   \n",
       "6769     37  51.565604   3.391266      1.835776       0.808303   0.296889   \n",
       "5713     27   7.756195   2.240452      0.848055       0.881694   0.413748   \n",
       "4626      7  12.596277   2.305350      1.429092       2.475099   0.940114   \n",
       "5897      2   1.380722   0.367982      0.225017       0.254739   0.215541   \n",
       "2478     12   3.235238   1.500663      0.961854       0.487098   0.146348   \n",
       "\n",
       "       F7_THETA  F7_ALPHA  F7_LOW_BETA  F7_HIGH_BETA  ...   F8_THETA  \\\n",
       "1332   0.885038  0.578492     0.466285      0.239371  ...   0.800284   \n",
       "6298   0.633558  0.486767     0.389702      0.455692  ...   0.871469   \n",
       "3276  23.593871  1.705054     1.081661      1.232416  ...  11.597608   \n",
       "5290   3.166249  2.514987     0.973730      0.419433  ...   2.315902   \n",
       "997    1.159595  0.428635     0.463035      0.699421  ...   2.426510   \n",
       "...         ...       ...          ...           ...  ...        ...   \n",
       "6769  19.835506  1.089665     0.737173      0.687855  ...   2.642095   \n",
       "5713   7.974846  1.066862     0.665752      0.486006  ...   7.430139   \n",
       "4626   2.770743  0.700636     0.681848      1.568421  ...   2.919247   \n",
       "5897   2.050639  0.539228     0.201793      0.455422  ...   0.557181   \n",
       "2478   3.692103  2.362193     2.142775      0.722593  ...  36.643787   \n",
       "\n",
       "      F8_ALPHA  F8_LOW_BETA  F8_HIGH_BETA  F8_GAMMA  AF4_THETA  AF4_ALPHA  \\\n",
       "1332  0.288642     0.144675      0.206214  0.229648   0.085342   0.022524   \n",
       "6298  0.469115     0.601600      0.269455  0.207066   1.218318   0.382762   \n",
       "3276  2.486005     0.388443      1.563786  1.344028  12.899495   3.239416   \n",
       "5290  2.599993     0.828052      0.294634  0.148104   1.685567   3.248761   \n",
       "997   2.457515     1.414658      1.308107  0.385595   2.318869   1.075982   \n",
       "...        ...          ...           ...       ...        ...        ...   \n",
       "6769  0.616125     0.234319      0.297825  0.266174  53.489877   4.621722   \n",
       "5713  4.179854     2.339862      0.663899  0.335339  25.352437   6.233271   \n",
       "4626  0.425634     0.571025      0.874110  0.416580  16.017680   1.519394   \n",
       "5897  0.693332     0.579581      0.239018  0.158849   2.682565   0.769564   \n",
       "2478  9.464797     3.646966      2.416778  0.659013   6.884388   2.696627   \n",
       "\n",
       "      AF4_LOW_BETA  AF4_HIGH_BETA  AF4_GAMMA  \n",
       "1332      0.020913       0.015468   0.018381  \n",
       "6298      0.806457       0.413249   0.250350  \n",
       "3276      0.455126       0.828596   0.464897  \n",
       "5290      1.279734       0.626797   0.236227  \n",
       "997       2.143163       2.837157   0.744531  \n",
       "...            ...            ...        ...  \n",
       "6769      2.171978       0.809025   0.263999  \n",
       "5713      1.161865       0.844477   0.775728  \n",
       "4626      1.255895       2.342372   1.076702  \n",
       "5897      0.454318       0.324629   0.216097  \n",
       "2478      2.163959       1.846503   0.522795  \n",
       "\n",
       "[4928 rows x 71 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8a2b4bb-4e0b-42e7-b310-43c08963974d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>F7_THETA</th>\n",
       "      <th>F7_ALPHA</th>\n",
       "      <th>F7_LOW_BETA</th>\n",
       "      <th>F7_HIGH_BETA</th>\n",
       "      <th>...</th>\n",
       "      <th>F8_THETA</th>\n",
       "      <th>F8_ALPHA</th>\n",
       "      <th>F8_LOW_BETA</th>\n",
       "      <th>F8_HIGH_BETA</th>\n",
       "      <th>F8_GAMMA</th>\n",
       "      <th>AF4_THETA</th>\n",
       "      <th>AF4_ALPHA</th>\n",
       "      <th>AF4_LOW_BETA</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.033470</td>\n",
       "      <td>2.028336</td>\n",
       "      <td>0.933330</td>\n",
       "      <td>6.659462</td>\n",
       "      <td>0.916482</td>\n",
       "      <td>1.824260</td>\n",
       "      <td>1.254074</td>\n",
       "      <td>0.634456</td>\n",
       "      <td>3.700502</td>\n",
       "      <td>...</td>\n",
       "      <td>10.334194</td>\n",
       "      <td>2.218516</td>\n",
       "      <td>1.273915</td>\n",
       "      <td>0.610819</td>\n",
       "      <td>0.342051</td>\n",
       "      <td>5.532071</td>\n",
       "      <td>2.337674</td>\n",
       "      <td>1.011535</td>\n",
       "      <td>1.609977</td>\n",
       "      <td>1.325849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6.828661</td>\n",
       "      <td>3.425307</td>\n",
       "      <td>1.405881</td>\n",
       "      <td>4.518988</td>\n",
       "      <td>0.532399</td>\n",
       "      <td>1.986457</td>\n",
       "      <td>1.560375</td>\n",
       "      <td>1.256536</td>\n",
       "      <td>3.083162</td>\n",
       "      <td>...</td>\n",
       "      <td>8.196053</td>\n",
       "      <td>3.192119</td>\n",
       "      <td>2.291647</td>\n",
       "      <td>0.731953</td>\n",
       "      <td>0.302914</td>\n",
       "      <td>11.453557</td>\n",
       "      <td>4.499370</td>\n",
       "      <td>1.867601</td>\n",
       "      <td>1.266913</td>\n",
       "      <td>0.623921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>13.394172</td>\n",
       "      <td>4.604422</td>\n",
       "      <td>1.378888</td>\n",
       "      <td>3.345854</td>\n",
       "      <td>0.468798</td>\n",
       "      <td>3.194034</td>\n",
       "      <td>1.656977</td>\n",
       "      <td>1.265359</td>\n",
       "      <td>2.396279</td>\n",
       "      <td>...</td>\n",
       "      <td>8.333990</td>\n",
       "      <td>3.374497</td>\n",
       "      <td>2.260097</td>\n",
       "      <td>0.858818</td>\n",
       "      <td>0.315853</td>\n",
       "      <td>20.202041</td>\n",
       "      <td>6.215337</td>\n",
       "      <td>1.977753</td>\n",
       "      <td>1.299966</td>\n",
       "      <td>0.530632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>42.181576</td>\n",
       "      <td>6.109872</td>\n",
       "      <td>0.419378</td>\n",
       "      <td>2.499464</td>\n",
       "      <td>0.982025</td>\n",
       "      <td>9.553105</td>\n",
       "      <td>1.213163</td>\n",
       "      <td>0.408726</td>\n",
       "      <td>1.556084</td>\n",
       "      <td>...</td>\n",
       "      <td>13.633903</td>\n",
       "      <td>2.008298</td>\n",
       "      <td>0.682593</td>\n",
       "      <td>0.877496</td>\n",
       "      <td>0.617408</td>\n",
       "      <td>57.783356</td>\n",
       "      <td>8.898400</td>\n",
       "      <td>0.909611</td>\n",
       "      <td>2.577918</td>\n",
       "      <td>0.928984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>33.202433</td>\n",
       "      <td>4.308125</td>\n",
       "      <td>0.370781</td>\n",
       "      <td>2.277905</td>\n",
       "      <td>0.980550</td>\n",
       "      <td>7.778650</td>\n",
       "      <td>0.882705</td>\n",
       "      <td>0.421524</td>\n",
       "      <td>1.462749</td>\n",
       "      <td>...</td>\n",
       "      <td>11.934303</td>\n",
       "      <td>1.572880</td>\n",
       "      <td>0.739357</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.590198</td>\n",
       "      <td>46.233436</td>\n",
       "      <td>6.497908</td>\n",
       "      <td>0.794796</td>\n",
       "      <td>2.854827</td>\n",
       "      <td>0.902377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>32</td>\n",
       "      <td>8.809801</td>\n",
       "      <td>2.691115</td>\n",
       "      <td>0.700470</td>\n",
       "      <td>0.355971</td>\n",
       "      <td>0.135588</td>\n",
       "      <td>4.754065</td>\n",
       "      <td>1.414664</td>\n",
       "      <td>0.733873</td>\n",
       "      <td>0.275685</td>\n",
       "      <td>...</td>\n",
       "      <td>3.156630</td>\n",
       "      <td>1.022644</td>\n",
       "      <td>0.371568</td>\n",
       "      <td>0.358461</td>\n",
       "      <td>0.276610</td>\n",
       "      <td>7.852246</td>\n",
       "      <td>2.320847</td>\n",
       "      <td>0.876808</td>\n",
       "      <td>0.645105</td>\n",
       "      <td>0.363037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>32</td>\n",
       "      <td>4.825134</td>\n",
       "      <td>1.969288</td>\n",
       "      <td>0.563214</td>\n",
       "      <td>0.358036</td>\n",
       "      <td>0.135428</td>\n",
       "      <td>3.344331</td>\n",
       "      <td>1.141357</td>\n",
       "      <td>0.805275</td>\n",
       "      <td>0.287915</td>\n",
       "      <td>...</td>\n",
       "      <td>3.010638</td>\n",
       "      <td>1.045846</td>\n",
       "      <td>0.456660</td>\n",
       "      <td>0.405954</td>\n",
       "      <td>0.314061</td>\n",
       "      <td>5.476381</td>\n",
       "      <td>1.840115</td>\n",
       "      <td>0.876011</td>\n",
       "      <td>0.666304</td>\n",
       "      <td>0.339792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>32</td>\n",
       "      <td>1.448134</td>\n",
       "      <td>0.569360</td>\n",
       "      <td>0.526131</td>\n",
       "      <td>0.369438</td>\n",
       "      <td>0.166980</td>\n",
       "      <td>1.372291</td>\n",
       "      <td>0.641029</td>\n",
       "      <td>0.686642</td>\n",
       "      <td>0.288760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929340</td>\n",
       "      <td>0.826974</td>\n",
       "      <td>0.409080</td>\n",
       "      <td>0.489482</td>\n",
       "      <td>0.361166</td>\n",
       "      <td>3.632138</td>\n",
       "      <td>0.880122</td>\n",
       "      <td>1.006690</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.345115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>37</td>\n",
       "      <td>19.891139</td>\n",
       "      <td>3.686975</td>\n",
       "      <td>0.514632</td>\n",
       "      <td>0.372545</td>\n",
       "      <td>0.141639</td>\n",
       "      <td>4.749370</td>\n",
       "      <td>1.807512</td>\n",
       "      <td>0.189985</td>\n",
       "      <td>0.468722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764684</td>\n",
       "      <td>1.063684</td>\n",
       "      <td>0.459404</td>\n",
       "      <td>0.267332</td>\n",
       "      <td>0.233134</td>\n",
       "      <td>14.151417</td>\n",
       "      <td>2.361383</td>\n",
       "      <td>0.646940</td>\n",
       "      <td>0.517115</td>\n",
       "      <td>0.358956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7035</th>\n",
       "      <td>37</td>\n",
       "      <td>1.758236</td>\n",
       "      <td>0.875683</td>\n",
       "      <td>0.315797</td>\n",
       "      <td>0.370315</td>\n",
       "      <td>0.130609</td>\n",
       "      <td>0.762570</td>\n",
       "      <td>0.577449</td>\n",
       "      <td>0.209972</td>\n",
       "      <td>0.204362</td>\n",
       "      <td>...</td>\n",
       "      <td>226.389658</td>\n",
       "      <td>224.684794</td>\n",
       "      <td>222.017970</td>\n",
       "      <td>185.340637</td>\n",
       "      <td>159.439485</td>\n",
       "      <td>1.498518</td>\n",
       "      <td>1.088431</td>\n",
       "      <td>0.483297</td>\n",
       "      <td>0.455888</td>\n",
       "      <td>0.248401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2112 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LABEL  AF3_THETA  AF3_ALPHA  AF3_LOW_BETA  AF3_HIGH_BETA  AF3_GAMMA  \\\n",
       "1         2   3.033470   2.028336      0.933330       6.659462   0.916482   \n",
       "4         2   6.828661   3.425307      1.405881       4.518988   0.532399   \n",
       "5         2  13.394172   4.604422      1.378888       3.345854   0.468798   \n",
       "11        2  42.181576   6.109872      0.419378       2.499464   0.982025   \n",
       "12        2  33.202433   4.308125      0.370781       2.277905   0.980550   \n",
       "...     ...        ...        ...           ...            ...        ...   \n",
       "7017     32   8.809801   2.691115      0.700470       0.355971   0.135588   \n",
       "7018     32   4.825134   1.969288      0.563214       0.358036   0.135428   \n",
       "7023     32   1.448134   0.569360      0.526131       0.369438   0.166980   \n",
       "7024     37  19.891139   3.686975      0.514632       0.372545   0.141639   \n",
       "7035     37   1.758236   0.875683      0.315797       0.370315   0.130609   \n",
       "\n",
       "      F7_THETA  F7_ALPHA  F7_LOW_BETA  F7_HIGH_BETA  ...    F8_THETA  \\\n",
       "1     1.824260  1.254074     0.634456      3.700502  ...   10.334194   \n",
       "4     1.986457  1.560375     1.256536      3.083162  ...    8.196053   \n",
       "5     3.194034  1.656977     1.265359      2.396279  ...    8.333990   \n",
       "11    9.553105  1.213163     0.408726      1.556084  ...   13.633903   \n",
       "12    7.778650  0.882705     0.421524      1.462749  ...   11.934303   \n",
       "...        ...       ...          ...           ...  ...         ...   \n",
       "7017  4.754065  1.414664     0.733873      0.275685  ...    3.156630   \n",
       "7018  3.344331  1.141357     0.805275      0.287915  ...    3.010638   \n",
       "7023  1.372291  0.641029     0.686642      0.288760  ...    0.929340   \n",
       "7024  4.749370  1.807512     0.189985      0.468722  ...    0.764684   \n",
       "7035  0.762570  0.577449     0.209972      0.204362  ...  226.389658   \n",
       "\n",
       "        F8_ALPHA  F8_LOW_BETA  F8_HIGH_BETA    F8_GAMMA  AF4_THETA  AF4_ALPHA  \\\n",
       "1       2.218516     1.273915      0.610819    0.342051   5.532071   2.337674   \n",
       "4       3.192119     2.291647      0.731953    0.302914  11.453557   4.499370   \n",
       "5       3.374497     2.260097      0.858818    0.315853  20.202041   6.215337   \n",
       "11      2.008298     0.682593      0.877496    0.617408  57.783356   8.898400   \n",
       "12      1.572880     0.739357      0.894378    0.590198  46.233436   6.497908   \n",
       "...          ...          ...           ...         ...        ...        ...   \n",
       "7017    1.022644     0.371568      0.358461    0.276610   7.852246   2.320847   \n",
       "7018    1.045846     0.456660      0.405954    0.314061   5.476381   1.840115   \n",
       "7023    0.826974     0.409080      0.489482    0.361166   3.632138   0.880122   \n",
       "7024    1.063684     0.459404      0.267332    0.233134  14.151417   2.361383   \n",
       "7035  224.684794   222.017970    185.340637  159.439485   1.498518   1.088431   \n",
       "\n",
       "      AF4_LOW_BETA  AF4_HIGH_BETA  AF4_GAMMA  \n",
       "1         1.011535       1.609977   1.325849  \n",
       "4         1.867601       1.266913   0.623921  \n",
       "5         1.977753       1.299966   0.530632  \n",
       "11        0.909611       2.577918   0.928984  \n",
       "12        0.794796       2.854827   0.902377  \n",
       "...            ...            ...        ...  \n",
       "7017      0.876808       0.645105   0.363037  \n",
       "7018      0.876011       0.666304   0.339792  \n",
       "7023      1.006690       0.999960   0.345115  \n",
       "7024      0.646940       0.517115   0.358956  \n",
       "7035      0.483297       0.455888   0.248401  \n",
       "\n",
       "[2112 rows x 71 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f7da8-4004-4845-91a7-c564e2ba65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d87faf2-5734-4cfc-81e4-29daf563fda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 17, 37, ..., 27, 27, 27], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b7daafb-d9e2-4505-bffa-78a06467b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 37, 37, 37], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48ad0d28-8416-4ea8-be82-b8264d3d4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric features: 70\n"
     ]
    }
   ],
   "source": [
    "# Transforming non numerical labels into numerical labels\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# encoding train labels \n",
    "encoder.fit(Y_train_label)\n",
    "Y_train = encoder.transform(Y_train_label)\n",
    "\n",
    "# encoding test labels \n",
    "encoder.fit(Y_test_label)\n",
    "Y_test = encoder.transform(Y_test_label)\n",
    "\n",
    "#Total Number of Continous and Categorical features in the training set\n",
    "num_cols = X_train._get_numeric_data().columns\n",
    "print(\"Number of numeric features:\",num_cols.size)\n",
    "#list(set(X_train.columns) - set(num_cols))\n",
    "\n",
    "\n",
    "names_of_predictors = list(X_train.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8032ea8a-2d8f-47e5-8e9a-32771dc453c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d35b16ae-7729-4393-add1-ca17cc1518e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma=0.001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = SVC(kernel='rbf', gamma=0.001, C=1000)\n",
    "#final_model = SVC(kernel='poly', gamma=0.001, C=1000)\n",
    "final_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "060fe2f9-94bb-4b8f-8566-be43ad716d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for SVM: 0.965300\n",
      "Testing  set score for SVM: 0.786932\n"
     ]
    }
   ],
   "source": [
    "Y_pred = final_model.predict(X_test)\n",
    "Y_pred_label = list(encoder.inverse_transform(Y_pred))\n",
    "\n",
    "print(\"Training set score for SVM: %f\" % final_model.score(X_train , Y_train))\n",
    "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test  , Y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "531d8308-78a6-4201-8b5f-46ac2d325a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87167822-cb4c-41de-b223-a9605083ddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5636d40-ccf6-46ea-9971-1761b3ff64a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9858ada7-26b6-4dce-96fc-7a3c4b2c840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\IMBA PC\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "y_score = clf.fit(X_train, Y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50fe60fe-7622-484b-a15f-1747280f1afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>F7_THETA</th>\n",
       "      <th>F7_ALPHA</th>\n",
       "      <th>F7_LOW_BETA</th>\n",
       "      <th>F7_HIGH_BETA</th>\n",
       "      <th>F7_GAMMA</th>\n",
       "      <th>...</th>\n",
       "      <th>F8_THETA</th>\n",
       "      <th>F8_ALPHA</th>\n",
       "      <th>F8_LOW_BETA</th>\n",
       "      <th>F8_HIGH_BETA</th>\n",
       "      <th>F8_GAMMA</th>\n",
       "      <th>AF4_THETA</th>\n",
       "      <th>AF4_ALPHA</th>\n",
       "      <th>AF4_LOW_BETA</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6256</th>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.849213</td>\n",
       "      <td>0.143045</td>\n",
       "      <td>0.177825</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.776716</td>\n",
       "      <td>0.318053</td>\n",
       "      <td>0.677775</td>\n",
       "      <td>0.455227</td>\n",
       "      <td>0.897437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724391</td>\n",
       "      <td>1.065701</td>\n",
       "      <td>0.322749</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.257977</td>\n",
       "      <td>1.150256</td>\n",
       "      <td>1.131571</td>\n",
       "      <td>0.472789</td>\n",
       "      <td>0.236763</td>\n",
       "      <td>0.204469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>3.561036</td>\n",
       "      <td>1.248834</td>\n",
       "      <td>0.402016</td>\n",
       "      <td>1.685657</td>\n",
       "      <td>1.889830</td>\n",
       "      <td>1.820449</td>\n",
       "      <td>0.887768</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>1.034733</td>\n",
       "      <td>0.597373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.937794</td>\n",
       "      <td>0.583892</td>\n",
       "      <td>0.450815</td>\n",
       "      <td>0.585681</td>\n",
       "      <td>0.630813</td>\n",
       "      <td>2.793595</td>\n",
       "      <td>0.719009</td>\n",
       "      <td>0.339058</td>\n",
       "      <td>1.253548</td>\n",
       "      <td>1.712881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1.095015</td>\n",
       "      <td>0.625003</td>\n",
       "      <td>0.433012</td>\n",
       "      <td>0.232953</td>\n",
       "      <td>0.076381</td>\n",
       "      <td>0.873730</td>\n",
       "      <td>0.619836</td>\n",
       "      <td>0.668202</td>\n",
       "      <td>0.249569</td>\n",
       "      <td>0.161224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.086927</td>\n",
       "      <td>0.812313</td>\n",
       "      <td>0.349884</td>\n",
       "      <td>0.517981</td>\n",
       "      <td>0.114014</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.030951</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.014983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>2.048056</td>\n",
       "      <td>2.531181</td>\n",
       "      <td>1.241439</td>\n",
       "      <td>2.332025</td>\n",
       "      <td>0.550160</td>\n",
       "      <td>0.826937</td>\n",
       "      <td>1.165857</td>\n",
       "      <td>0.552366</td>\n",
       "      <td>0.695373</td>\n",
       "      <td>0.536284</td>\n",
       "      <td>...</td>\n",
       "      <td>4.017442</td>\n",
       "      <td>1.339636</td>\n",
       "      <td>0.879380</td>\n",
       "      <td>2.063724</td>\n",
       "      <td>0.599968</td>\n",
       "      <td>1.997180</td>\n",
       "      <td>4.318983</td>\n",
       "      <td>2.228683</td>\n",
       "      <td>4.503985</td>\n",
       "      <td>0.933629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>0.916234</td>\n",
       "      <td>0.489746</td>\n",
       "      <td>0.654671</td>\n",
       "      <td>0.217297</td>\n",
       "      <td>0.156947</td>\n",
       "      <td>1.383343</td>\n",
       "      <td>0.501079</td>\n",
       "      <td>0.776464</td>\n",
       "      <td>0.749042</td>\n",
       "      <td>0.393293</td>\n",
       "      <td>...</td>\n",
       "      <td>1.652656</td>\n",
       "      <td>0.507012</td>\n",
       "      <td>1.010707</td>\n",
       "      <td>0.258741</td>\n",
       "      <td>0.274295</td>\n",
       "      <td>2.161136</td>\n",
       "      <td>0.407456</td>\n",
       "      <td>1.284984</td>\n",
       "      <td>0.320132</td>\n",
       "      <td>0.209659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>2.941636</td>\n",
       "      <td>1.434361</td>\n",
       "      <td>0.359110</td>\n",
       "      <td>0.426032</td>\n",
       "      <td>0.217967</td>\n",
       "      <td>2.681471</td>\n",
       "      <td>1.051165</td>\n",
       "      <td>0.658066</td>\n",
       "      <td>0.400820</td>\n",
       "      <td>0.183097</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136089</td>\n",
       "      <td>3.492337</td>\n",
       "      <td>2.853636</td>\n",
       "      <td>0.721638</td>\n",
       "      <td>0.429971</td>\n",
       "      <td>4.094978</td>\n",
       "      <td>2.381994</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>0.581087</td>\n",
       "      <td>0.328790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763</th>\n",
       "      <td>35.507696</td>\n",
       "      <td>5.779094</td>\n",
       "      <td>2.805934</td>\n",
       "      <td>0.728369</td>\n",
       "      <td>0.142891</td>\n",
       "      <td>13.072971</td>\n",
       "      <td>1.055892</td>\n",
       "      <td>1.662943</td>\n",
       "      <td>0.816902</td>\n",
       "      <td>0.275374</td>\n",
       "      <td>...</td>\n",
       "      <td>2.497251</td>\n",
       "      <td>0.451089</td>\n",
       "      <td>0.469619</td>\n",
       "      <td>0.763812</td>\n",
       "      <td>0.211456</td>\n",
       "      <td>33.214026</td>\n",
       "      <td>3.304922</td>\n",
       "      <td>1.406709</td>\n",
       "      <td>0.775797</td>\n",
       "      <td>0.299266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0.937816</td>\n",
       "      <td>1.144966</td>\n",
       "      <td>1.254642</td>\n",
       "      <td>2.179178</td>\n",
       "      <td>0.964822</td>\n",
       "      <td>0.988851</td>\n",
       "      <td>0.696238</td>\n",
       "      <td>0.353891</td>\n",
       "      <td>0.681386</td>\n",
       "      <td>0.315350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103930</td>\n",
       "      <td>1.342256</td>\n",
       "      <td>0.537233</td>\n",
       "      <td>0.681767</td>\n",
       "      <td>0.308752</td>\n",
       "      <td>0.990176</td>\n",
       "      <td>2.444644</td>\n",
       "      <td>0.678045</td>\n",
       "      <td>2.081431</td>\n",
       "      <td>1.372917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>1.025311</td>\n",
       "      <td>0.790290</td>\n",
       "      <td>0.761975</td>\n",
       "      <td>0.238270</td>\n",
       "      <td>0.184917</td>\n",
       "      <td>1.381843</td>\n",
       "      <td>1.439977</td>\n",
       "      <td>0.993738</td>\n",
       "      <td>0.588498</td>\n",
       "      <td>0.547966</td>\n",
       "      <td>...</td>\n",
       "      <td>1.478954</td>\n",
       "      <td>0.707603</td>\n",
       "      <td>0.890104</td>\n",
       "      <td>0.429664</td>\n",
       "      <td>0.389146</td>\n",
       "      <td>3.167747</td>\n",
       "      <td>1.073649</td>\n",
       "      <td>1.510128</td>\n",
       "      <td>0.559347</td>\n",
       "      <td>0.333705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>1.106616</td>\n",
       "      <td>1.222154</td>\n",
       "      <td>0.305071</td>\n",
       "      <td>0.243915</td>\n",
       "      <td>0.153475</td>\n",
       "      <td>1.680538</td>\n",
       "      <td>1.494213</td>\n",
       "      <td>0.304987</td>\n",
       "      <td>0.173402</td>\n",
       "      <td>0.153658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.194985</td>\n",
       "      <td>1.830153</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.311582</td>\n",
       "      <td>0.114195</td>\n",
       "      <td>1.321173</td>\n",
       "      <td>3.677223</td>\n",
       "      <td>0.484303</td>\n",
       "      <td>1.097748</td>\n",
       "      <td>0.806084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4928 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AF3_THETA  AF3_ALPHA  AF3_LOW_BETA  AF3_HIGH_BETA  AF3_GAMMA   F7_THETA  \\\n",
       "6256   0.423073   0.849213      0.143045       0.177825   0.146152   0.776716   \n",
       "568    3.561036   1.248834      0.402016       1.685657   1.889830   1.820449   \n",
       "1531   1.095015   0.625003      0.433012       0.232953   0.076381   0.873730   \n",
       "4954   2.048056   2.531181      1.241439       2.332025   0.550160   0.826937   \n",
       "6145   0.916234   0.489746      0.654671       0.217297   0.156947   1.383343   \n",
       "...         ...        ...           ...            ...        ...        ...   \n",
       "5124   2.941636   1.434361      0.359110       0.426032   0.217967   2.681471   \n",
       "6763  35.507696   5.779094      2.805934       0.728369   0.142891  13.072971   \n",
       "3538   0.937816   1.144966      1.254642       2.179178   0.964822   0.988851   \n",
       "5968   1.025311   0.790290      0.761975       0.238270   0.184917   1.381843   \n",
       "2388   1.106616   1.222154      0.305071       0.243915   0.153475   1.680538   \n",
       "\n",
       "      F7_ALPHA  F7_LOW_BETA  F7_HIGH_BETA  F7_GAMMA  ...  F8_THETA  F8_ALPHA  \\\n",
       "6256  0.318053     0.677775      0.455227  0.897437  ...  1.724391  1.065701   \n",
       "568   0.887768     0.247769      1.034733  0.597373  ...  1.937794  0.583892   \n",
       "1531  0.619836     0.668202      0.249569  0.161224  ...  2.086927  0.812313   \n",
       "4954  1.165857     0.552366      0.695373  0.536284  ...  4.017442  1.339636   \n",
       "6145  0.501079     0.776464      0.749042  0.393293  ...  1.652656  0.507012   \n",
       "...        ...          ...           ...       ...  ...       ...       ...   \n",
       "5124  1.051165     0.658066      0.400820  0.183097  ...  7.136089  3.492337   \n",
       "6763  1.055892     1.662943      0.816902  0.275374  ...  2.497251  0.451089   \n",
       "3538  0.696238     0.353891      0.681386  0.315350  ...  1.103930  1.342256   \n",
       "5968  1.439977     0.993738      0.588498  0.547966  ...  1.478954  0.707603   \n",
       "2388  1.494213     0.304987      0.173402  0.153658  ...  1.194985  1.830153   \n",
       "\n",
       "      F8_LOW_BETA  F8_HIGH_BETA  F8_GAMMA  AF4_THETA  AF4_ALPHA  AF4_LOW_BETA  \\\n",
       "6256     0.322749      0.323232  0.257977   1.150256   1.131571      0.472789   \n",
       "568      0.450815      0.585681  0.630813   2.793595   0.719009      0.339058   \n",
       "1531     0.349884      0.517981  0.114014   0.071300   0.030951      0.024047   \n",
       "4954     0.879380      2.063724  0.599968   1.997180   4.318983      2.228683   \n",
       "6145     1.010707      0.258741  0.274295   2.161136   0.407456      1.284984   \n",
       "...           ...           ...       ...        ...        ...           ...   \n",
       "5124     2.853636      0.721638  0.429971   4.094978   2.381994      0.998692   \n",
       "6763     0.469619      0.763812  0.211456  33.214026   3.304922      1.406709   \n",
       "3538     0.537233      0.681767  0.308752   0.990176   2.444644      0.678045   \n",
       "5968     0.890104      0.429664  0.389146   3.167747   1.073649      1.510128   \n",
       "2388     0.156400      0.311582  0.114195   1.321173   3.677223      0.484303   \n",
       "\n",
       "      AF4_HIGH_BETA  AF4_GAMMA  \n",
       "6256       0.236763   0.204469  \n",
       "568        1.253548   1.712881  \n",
       "1531       0.015958   0.014983  \n",
       "4954       4.503985   0.933629  \n",
       "6145       0.320132   0.209659  \n",
       "...             ...        ...  \n",
       "5124       0.581087   0.328790  \n",
       "6763       0.775797   0.299266  \n",
       "3538       2.081431   1.372917  \n",
       "5968       0.559347   0.333705  \n",
       "2388       1.097748   0.806084  \n",
       "\n",
       "[4928 rows x 70 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4d0f5ac-6390-485a-8bfa-24e3f5e58ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\IMBAPC~1\\AppData\\Local\\Temp/ipykernel_4708/2618909697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \"\"\"\n\u001b[1;32m--> 913\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    914\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0m\u001b[0;32m    260\u001b[0m                             \" a valid collection.\" % x)\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[i], Y_pred[i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805fd2b-8ae6-47c3-a661-8f66e9d95ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# classifier\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
